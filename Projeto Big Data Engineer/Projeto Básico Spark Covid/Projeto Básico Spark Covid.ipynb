{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de conclusão do treinamento de Big Data Engineer da Semantix\n",
    "Autor: Juvenal Fonseca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Enviar os dados para o hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copia os dados do covid da estação de trabalho para o container do jupyter-spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docker cp /home/nal/treinamentos/spark/input/covid/ jupyter-spark:/home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copia os dados do covid para o hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -put /home/covid/ /user/juvenal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista a pasta de covid do destino para checar se arquivos foram copiados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   2 root supergroup   62492959 2022-04-19 11:31 /user/juvenal/covid/HIST_PAINEL_COVIDBR_2020_Parte1_06jul2021.csv\r\n",
      "-rw-r--r--   2 root supergroup   76520681 2022-04-19 11:31 /user/juvenal/covid/HIST_PAINEL_COVIDBR_2020_Parte2_06jul2021.csv\r\n",
      "-rw-r--r--   2 root supergroup   91120916 2022-04-19 11:31 /user/juvenal/covid/HIST_PAINEL_COVIDBR_2021_Parte1_06jul2021.csv\r\n",
      "-rw-r--r--   2 root supergroup    3046774 2022-04-19 11:31 /user/juvenal/covid/HIST_PAINEL_COVIDBR_2021_Parte2_06jul2021.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/juvenal/covid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Otimizar todos os dados do hdfs para uma tabela Hive particionada por município"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria o banco de dados saude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS saude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ler dados do hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza importações necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria estrutura de schema para ler arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_field = [\n",
    "    StructField(\"regiao\"               , StringType() ), \n",
    "    StructField(\"estado\"               , StringType() ),\n",
    "    StructField(\"municipio\"            , StringType() ),\n",
    "    StructField(\"coduf\"                , IntegerType()), \n",
    "    StructField(\"codmun\"               , IntegerType()),\n",
    "    StructField(\"codRegiaoSaude\"       , IntegerType()),\n",
    "    StructField(\"nomeRegiaoSaude\"      , StringType() ), \n",
    "    StructField(\"data\"                 , DateType()   ),\n",
    "    StructField(\"semanaEpi\"            , IntegerType()),\n",
    "    StructField(\"populacaoTCU2019\"     , DecimalType()), \n",
    "    StructField(\"casosAcumulado\"       , IntegerType()),\n",
    "    StructField(\"casosNovos\"           , IntegerType()),\n",
    "    StructField(\"obitosAcumulado\"      , StringType() ), \n",
    "    StructField(\"obitosNovos\"          , IntegerType()),\n",
    "    StructField(\"recuperadosNovos\"     , IntegerType()),\n",
    "    StructField(\"emAcompanhamentoNovos\", IntegerType()), \n",
    "    StructField(\"interiorMetropolitana\", IntegerType())\n",
    "]\n",
    "\n",
    "struct_type = StructType(struct_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza leitura dos arquivos csv no diretório do hdfs e atribui ao DataFrame dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = spark \\\n",
    ".read \\\n",
    ".csv(path     = \"/user/juvenal/covid\", \n",
    "     sep      = \";\", \n",
    "     header   = \"true\", \n",
    "     mode     = \"overwrite\", \n",
    "     encoding = \"UTF-8\", \n",
    "     schema   = struct_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvar dados no hiver particionado por municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.write.partitionBy(\"municipio\").mode(\"overwrite\").saveAsTable(\"saude.covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Criar as 3 vizualizações pelo Spark com os dados enviados para o HDFS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibe o schema do DataFrame dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- regiao: string (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- coduf: integer (nullable = true)\n",
      " |-- codmun: integer (nullable = true)\n",
      " |-- codRegiaoSaude: integer (nullable = true)\n",
      " |-- nomeRegiaoSaude: string (nullable = true)\n",
      " |-- data: date (nullable = true)\n",
      " |-- semanaEpi: integer (nullable = true)\n",
      " |-- populacaoTCU2019: decimal(10,0) (nullable = true)\n",
      " |-- casosAcumulado: integer (nullable = true)\n",
      " |-- casosNovos: integer (nullable = true)\n",
      " |-- obitosAcumulado: string (nullable = true)\n",
      " |-- obitosNovos: integer (nullable = true)\n",
      " |-- recuperadosNovos: integer (nullable = true)\n",
      " |-- emAcompanhamentoNovos: integer (nullable = true)\n",
      " |-- interiorMetropolitana: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dados.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleciona colunas do DataFrame dados utilizado nas operações;\n",
    "\n",
    "Filtra os dados por região Brasil, já que as informações solicitadas são encontradas nessas regiões de forma acumulada;\n",
    "\n",
    "Identifica a última data do boletim informativo para recuperar os dados acumulados;\n",
    "\n",
    "Filtra os registros que correspondem a última data do boletim informativo;\n",
    "\n",
    "Remove as colunas não mais necessárias do DataFrame;\n",
    "\n",
    "Calcula o percentual de letalidade e os índices de mortalidade e incidência;\n",
    "\n",
    "Corrige o separador decimal para o padrão brasileiro;\n",
    "\n",
    "Renomeia colunas para melhor exibição;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy('regiao').orderBy(\"regiao\")\n",
    "\n",
    "resultado = dados \\\n",
    ".select( col(\"regiao\"), col(\"data\"), col(\"recuperadosNovos\"), col(\"emAcompanhamentoNovos\"), col(\"casosAcumulado\"), col(\"casosNovos\"), col(\"obitosAcumulado\"), col(\"obitosNovos\"), col(\"populacaoTCU2019\") ) \\\n",
    ".where( (col(\"regiao\") == \"Brasil\")          ) \\\n",
    ".withColumn( 'max_data', max('data').over(w) ) \\\n",
    ".where( col(\"data\") == col(\"max_data\")       ) \\\n",
    ".withColumn( 'id', row_number().over(w)      ) \\\n",
    ".drop(\"regiao\", \"data\", \"max_data\")            \\\n",
    ".withColumn(\"Letalidade\" , format_number(((col(\"obitosAcumulado\")/col(\"casosAcumulado\"  ))*100   ),1).alias(\"Letalidade\" ) ) \\\n",
    ".withColumn(\"Mortalidade\", format_number(((col(\"obitosAcumulado\")/col(\"populacaoTCU2019\"))*100000),1).alias(\"Mortalidade\") ) \\\n",
    ".withColumn(\"Incidencia\" , format_number(((col(\"casosAcumulado\" )/col(\"populacaoTCU2019\"))*100000),1).alias(\"Incidência\" ) ) \\\n",
    ".withColumn('Letalidade' , translate('Letalidade' , '\\.,', '\\,')) \\\n",
    ".withColumn('Mortalidade', translate('Mortalidade', '\\.,', '\\,')) \\\n",
    ".withColumn('Incidencia' , translate('Incidencia' , '\\.,', '\\,')) \\\n",
    ".withColumnRenamed(\"recuperadosNovos\"     , \"Casos recuperados\" ) \\\n",
    ".withColumnRenamed(\"emAcompanhamentoNovos\", \"Em acompanhamento\" ) \\\n",
    ".withColumnRenamed(\"casosAcumulado\"       , \"Acumulado\"         ) \\\n",
    ".withColumnRenamed(\"casosNovos\"           , \"Casos novos\"       ) \\\n",
    ".withColumnRenamed(\"obitosAcumulado\"      , \"Óbitos Acumulados\" ) \\\n",
    ".withColumnRenamed(\"obitosNovos\"          , \"Óbitos Casos novos\") \\\n",
    ".withColumnRenamed(\"Incidencia\"           , \"Incidência\"        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualização 1 do Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de pessoas recuperadas e em acompanhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|Casos recuperados|Em acompanhamento|\n",
      "+-----------------+-----------------+\n",
      "|         17262646|          1065477|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_1 = resultado \\\n",
    ".select(col(\"Casos recuperados\"), col(\"Em acompanhamento\"))\n",
    "\n",
    "view_1.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualização 2 do Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de casos acumulados, novos casos (diário) e incidência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+\n",
      "|Acumulado|Casos novos|Incidência|\n",
      "+---------+-----------+----------+\n",
      "| 18855015|      62504|    8972,3|\n",
      "+---------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_2 = resultado \\\n",
    ".select(col(\"Acumulado\"), col(\"Casos novos\"), col(\"Incidência\"))\n",
    "\n",
    "view_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualização 3 do Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de óbitos, novos casos de óbito, letalidade e mortalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+----------+-----------+\n",
      "|Óbitos Acumulados|Óbitos Casos novos|Letalidade|Mortalidade|\n",
      "+-----------------+------------------+----------+-----------+\n",
      "|           526892|              1780|       2,8|      250,7|\n",
      "+-----------------+------------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_3 = resultado \\\n",
    ".select(col(\"id\"), col(\"Óbitos Acumulados\"), col(\"Óbitos Casos novos\"), col(\"Letalidade\"), col(\"Mortalidade\"))\n",
    "\n",
    "view_3.drop(\"id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Salvar a primeira visualização como tabela Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvw1 = view_1 \\\n",
    ".withColumnRenamed(\"Casos recuperados\",\"casosRecuperados\") \\\n",
    ".withColumnRenamed(\"Em acompanhamento\",\"emAcompanhamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvw1.write.mode(\"overwrite\").saveAsTable(\"saude.view_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Salvar a segunda visualização com formato parquet e compressão snappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvw2 = view_2 \\\n",
    ".withColumnRenamed(\"Acumulado\"  ,\"acumulado\") \\\n",
    ".withColumnRenamed(\"Casos novos\",\"casosNovos\") \\\n",
    ".withColumnRenamed(\"Incidência\" ,\"incidencia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvw2.write.saveAsTable(name=\"saude.view_2\", format=\"parquet\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Salvar a terceira visualização em um tópico no Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria o tópico topicCovid a partir da sua estação de trabalho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docker exec -it kafka kafka-topics.sh kafka-topics --bootstrap-server kafka:9092 --topic topicCovid --create --partitions 1 --replication-factor 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria o DataFrame df a partir do resultado do DataFrame view_3 renomeando os seus campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvw3 = view_3 \\\n",
    ".withColumnRenamed(\"id\"                ,\"value\"            ) \\\n",
    ".withColumnRenamed(\"Óbitos Acumulados\" ,\"obitosAcumulado\"  ) \\\n",
    ".withColumnRenamed(\"Óbitos Casos novos\",\"obitosCasosNovos\" ) \\\n",
    ".withColumnRenamed(\"Letalidade\"        ,\"letalidade\"       ) \\\n",
    ".withColumnRenamed(\"Mortalidade\"       ,\"mortalidade\"      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Escreve no tópico topicCovid do Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvw3.selectExpr(\"CAST(value AS STRING)\") \\\n",
    ".write \\\n",
    ".format(\"kafka\") \\\n",
    ".option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    ".option(\"topic\", \"topicCovid\") \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ler do tópico topicCovid do Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfK = spark \\\n",
    ".read \\\n",
    ".format(\"kafka\") \\\n",
    ".option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    ".option(\"subscribe\", \"topicCovid\") \\\n",
    ".option(\"startingOffsets\", \"earliest\")\\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exibe o histórico do tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+------+--------------------+-------------+\n",
      "| key|value|     topic|partition|offset|           timestamp|timestampType|\n",
      "+----+-----+----------+---------+------+--------------------+-------------+\n",
      "|null| [31]|topicCovid|        0|     0|2022-04-20 14:16:...|            0|\n",
      "|null| [31]|topicCovid|        0|     1|2022-04-20 14:21:...|            0|\n",
      "+----+-----+----------+---------+------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfK.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Criar a visualização pelo Spark com os dados enviados para o HDFS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sintese_de_casos_covid.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleciona colunas do DataFrame dados utilizado nas operações;\n",
    "\n",
    "Filtra os dados que não tenham código de município, já que as informações solicitadas são encontradas nas regiões de forma acumulada;\n",
    "\n",
    "Identifica a última data do boletim informativo para recuperar os dados acumulados;\n",
    "\n",
    "Filtra os registros que corresponde a última data do boletim informativo;\n",
    "\n",
    "Remove as colunas não mais necessárias do DataFrame;\n",
    "\n",
    "Agrupa os registros por região e data, já que cada região tem mais de um estado e esses registros precisam ser somados;\n",
    "\n",
    "Calcula os índices de mortalidade e incidência;\n",
    "\n",
    "Corrige o separador decimal para o padrão brasileiro;\n",
    "\n",
    "Renomeia colunas para melhor exibição;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy('regiao').orderBy(\"regiao\")\n",
    "\n",
    "resultado_geral = dados \\\n",
    ".select( col(\"municipio\"), col(\"regiao\"), col(\"data\"), col(\"casosAcumulado\"), col(\"obitosAcumulado\"), col(\"populacaoTCU2019\") ) \\\n",
    ".withColumn( 'max_data', max('data').over(w) ) \\\n",
    ".where( (col(\"data\") == col(\"max_data\")) & (col(\"codmun\").isNull()) ) \\\n",
    ".drop(\"max_data\")            \\\n",
    ".groupBy(\"regiao\", \"data\") \\\n",
    ".agg(sum(\"casosAcumulado\").alias(\"casosAcumulado\"), sum(\"obitosAcumulado\").alias(\"obitosAcumulado\"), sum(\"populacaoTCU2019\").alias(\"populacaoTCU2019\")) \\\n",
    ".withColumn(\"mortalidade\", format_number(((col(\"obitosAcumulado\")/col(\"populacaoTCU2019\"))*100000),1).alias(\"Mortalidade\") ) \\\n",
    ".withColumn(\"incidencia\" , format_number(((col(\"casosAcumulado\" )/col(\"populacaoTCU2019\"))*100000),1).alias(\"Incidência\" ) ) \\\n",
    ".withColumn('mortalidade'    , translate('mortalidade', '\\.,', '\\,')) \\\n",
    ".withColumn('incidencia'     , translate('incidencia' , '\\.,', '\\,')) \\\n",
    ".withColumn('obitosAcumulado', translate('incidencia' , '\\.,', '\\ ')) \\\n",
    ".drop(\"populacaoTCU2019\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------+----------------------+-----------------------+-----------+\n",
      "|      Região|   Casos|Óbitos|Incidência/100mil hab.|Mortalidade/100mil hab.|Atualização|\n",
      "+------------+--------+------+----------------------+-----------------------+-----------+\n",
      "|    Nordeste| 4455737| 78073|                7807,3|                  188,9| 2021-07-06|\n",
      "|         Sul| 3611041|120464|               12046,4|                  269,2| 2021-07-06|\n",
      "|     Sudeste| 7138803| 80782|                8078,2|                  277,6| 2021-07-06|\n",
      "|Centro-Oeste| 1916619|117605|               11760,5|                  301,9| 2021-07-06|\n",
      "|      Brasil|18855015| 89723|                8972,3|                  250,7| 2021-07-06|\n",
      "|       Norte| 1732815| 94016|                9401,6|                  237,9| 2021-07-06|\n",
      "+------------+--------+------+----------------------+-----------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultado_geral.select(col(\"regiao\").alias(\"Região\"), col(\"casosAcumulado\").alias(\"Casos\"), col(\"obitosAcumulado\").alias(\"Óbitos\"), col(\"incidencia\").alias(\"Incidência/100mil hab.\"), col(\"mortalidade\").alias(\"Mortalidade/100mil hab.\"), col(\"data\").alias(\"Atualização\")) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Salvar a visualização do exercício 6 em um tópico no Elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importa a biblioteca requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define variáveis para utilização na requisição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "server  = \"http://elasticsearch:9200\"\n",
    "headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "index   = \"covid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupera id do DataFrame para geração da url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = dfvw3.toPandas().value[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gera url da requisição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = server + \"/\" + index + \"/\" + \"_doc\" + \"/\" + str(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define o documento da requisição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = dfvw3.select(\"*\").drop(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dfe.toJSON().first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realiza a requisição para o elastic para incluir o documento no índice codiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post(url=url, data=doc, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exibe resposta da requisição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'covid',\n",
       " '_type': '_doc',\n",
       " '_id': '1',\n",
       " '_version': 2,\n",
       " 'result': 'updated',\n",
       " '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       " '_seq_no': 2,\n",
       " '_primary_term': 1}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consulta o documento enviado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'covid',\n",
       " '_type': '_doc',\n",
       " '_id': '1',\n",
       " '_version': 2,\n",
       " '_seq_no': 2,\n",
       " '_primary_term': 1,\n",
       " 'found': True,\n",
       " '_source': {'obitosAcumulado': '526892',\n",
       "  'obitosCasosNovos': 1780,\n",
       "  'letalidade': '2,8',\n",
       "  'mortalidade': '250,7'}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Criar um dashboard no Elastic para visualização dos novos dados enviados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela criada com os dados do elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data_table_covid.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
